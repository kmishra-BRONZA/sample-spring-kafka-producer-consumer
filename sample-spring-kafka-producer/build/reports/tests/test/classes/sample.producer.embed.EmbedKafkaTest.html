<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=edge"/>
<title>Test results - Class sample.producer.embed.EmbedKafkaTest</title>
<link href="../css/base-style.css" rel="stylesheet" type="text/css"/>
<link href="../css/style.css" rel="stylesheet" type="text/css"/>
<script src="../js/report.js" type="text/javascript"></script>
</head>
<body>
<div id="content">
<h1>Class sample.producer.embed.EmbedKafkaTest</h1>
<div class="breadcrumbs">
<a href="../index.html">all</a> &gt; 
<a href="../packages/sample.producer.embed.html">sample.producer.embed</a> &gt; EmbedKafkaTest</div>
<div id="summary">
<table>
<tr>
<td>
<div class="summaryGroup">
<table>
<tr>
<td>
<div class="infoBox" id="tests">
<div class="counter">2</div>
<p>tests</p>
</div>
</td>
<td>
<div class="infoBox" id="failures">
<div class="counter">0</div>
<p>failures</p>
</div>
</td>
<td>
<div class="infoBox" id="ignored">
<div class="counter">0</div>
<p>ignored</p>
</div>
</td>
<td>
<div class="infoBox" id="duration">
<div class="counter">3.054s</div>
<p>duration</p>
</div>
</td>
</tr>
</table>
</div>
</td>
<td>
<div class="infoBox success" id="successRate">
<div class="percent">100%</div>
<p>successful</p>
</div>
</td>
</tr>
</table>
</div>
<div id="tabs">
<ul class="tabLinks">
<li>
<a href="#tab0">Tests</a>
</li>
<li>
<a href="#tab1">Standard output</a>
</li>
</ul>
<div id="tab0" class="tab">
<h2>Tests</h2>
<table>
<thead>
<tr>
<th>Test</th>
<th>Duration</th>
<th>Result</th>
</tr>
</thead>
<tr>
<td class="success">testEmbeddedRawKafka</td>
<td>0.038s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testSpringKafka</td>
<td>3.016s</td>
<td class="success">passed</td>
</tr>
</table>
</div>
<div id="tab1" class="tab">
<h2>Standard output</h2>
<span class="code">
<pre>2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:host.name=10.88.32.46
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.version=1.8.0_301
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.vendor=Oracle Corporation
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_301.jdk/Contents/Home/jre
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.class.path=/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer/build/classes/test:/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer/build/resources/test:/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer/build/classes/main:/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer/build/resources/main:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/0.10.2.0/c20571ff756fcf8f4a7f76fc7b23707a4c14a67d/kafka-clients-0.10.2.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/1.2.2.RELEASE/3b75bf653f8752b6f1a89a490ea101113cf1b655/spring-kafka-1.2.2.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/1.5.4.RELEASE/5d6c554f34b20dffcbdfc7edf9b80956e2dace/spring-boot-starter-web-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.google.guava/guava/20.0/89507701249388e1ed5ddcf8c41f4ce1be7831ef/guava-20.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/1.5.4.RELEASE/a764033c4be6e73310a6b12604a37c20d3bd0176/spring-boot-starter-test-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka-test/1.2.2.RELEASE/6a21241085c019ec48cd6e4448bc79ae26e04be2/spring-kafka-test-1.2.2.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/net.jpountz.lz4/lz4/1.3.0/c708bb2590c0652a642236ef45d9f99ff842a2ce/lz4-1.3.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.2.6/48d92871ca286a47f230feb375f0bbffa83b85f6/snappy-java-1.1.2.6.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.25/da76ca59f6a57ee3102f8f9bd9cee742973efa8a/slf4j-api-1.7.25.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.3.9.RELEASE/a8c3bc6271b67102bc192e530257d3347e8d7b93/spring-messaging-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.2.0.RELEASE/4e2b3ea37df07ef6fd905696f1aa5d50128c2782/spring-retry-1.2.0.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/0.10.2.0/32bc203617ebd2f0802c85b91bb241dbe72faa7f/kafka-clients-0.10.2.0-test.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/1.5.4.RELEASE/74d5aa641503ddd12833c82cc19b295f9f40e8fa/spring-boot-starter-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/1.5.4.RELEASE/d7e26f1d0e594bd1aab7da227649fc12c1958416/spring-boot-starter-tomcat-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/5.3.5.Final/622a9bcef2eed6d41b5b8e0662c36212009e375/hibernate-validator-5.3.5.Final.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.8.8/bf88c7b27e95cbadce4e7c316a56c3efffda8026/jackson-databind-2.8.8.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.3.9.RELEASE/91dae64c4280093ad5fb4736a10913c9233479c1/spring-web-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.3.9.RELEASE/ca80b4a00abc388d8046bf372099f35564371c47/spring-webmvc-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-test/1.5.4.RELEASE/a7a68089a6cf35db5587029e5c163466dadf7c5b/spring-boot-test-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-test-autoconfigure/1.5.4.RELEASE/5c751eb6cfa58c86ba4ffc4c3334faf4331d5385/spring-boot-test-autoconfigure-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.jayway.jsonpath/json-path/2.2.0/22290d17944bd239fabf5ac69005a60a7ecbbbcb/json-path-2.2.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/junit/junit/4.12/2973d150c0dc1fefe998f834810d68f278ea58ec/junit-4.12.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.assertj/assertj-core/2.6.0/b532c3fc4f66bcfee4989a3514f1cd56203a33ad/assertj-core-2.6.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.10.19/e8546f5bef4e061d8dd73895b4e8f40e3fe6effe/mockito-core-1.10.19.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-library/1.3/4785a3c21320980282f9f33d0d1264a69040538f/hamcrest-library-1.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.skyscreamer/jsonassert/1.4.0/9cdbb373a06f6513e51e8c545ee6a5e981463edb/jsonassert-1.4.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.3.9.RELEASE/430b7298bfb85d66fb61e19ca8f06231b911e9f5/spring-core-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.3.9.RELEASE/35bf4c38c9245f5baeeda4bea7c41f4f33c5daf3/spring-test-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.3.9.RELEASE/daa5abf3779c8cad1a2910e1ea08e4272489d8ae/spring-beans-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka_2.11/0.10.2.0/1340a7ab7db442bc00be7eac85c395555347e5f1/kafka_2.11-0.10.2.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka_2.11/0.10.2.0/6ccefda962770dcc94350288bd0b56be9e266395/kafka_2.11-0.10.2.0-test.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.3.9.RELEASE/a186823724f03b98becd5f93b1fa107fe6f7a7ff/spring-context-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.5.4.RELEASE/cf51bb0751c1362a417eb59824d27d2907780d2/spring-boot-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.5.4.RELEASE/5591fa7358d950f374532c7d92dccf113ebfa1bb/spring-boot-autoconfigure-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/1.5.4.RELEASE/6b4364cfee82890ce9a9c2c59066f3a6e525debd/spring-boot-starter-logging-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.17/7a27ea250c5130b2922b86dea63cbb1cc10a660c/snakeyaml-1.17.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/8.5.15/f197a93ae66212767b004fd93d7a1a8ea62bc3fa/tomcat-embed-core-8.5.15.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/8.5.15/e4000e5386056eeebb43bf71e7d30c58d2473166/tomcat-embed-el-8.5.15.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/8.5.15/a92b066b0ea9ee1cb05b7d5e4bfed4ad8898f741/tomcat-embed-websocket-8.5.15.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.1.0.Final/8613ae82954779d518631e05daa73a6a954817d5/validation-api-1.1.0.Final.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.1.Final/c46217ab74b532568c0ed31dc599db3048bd1b67/jboss-logging-3.3.1.Final.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.3.3/864c8e370a691e343210cc7c532fc198cee460d8/classmate-1.3.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.8.0/45b426f7796b741035581a176744d91090e2e6fb/jackson-annotations-2.8.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.8.8/d478fb6de45a7c3d2cad07c8ad70c7f0a797a020/jackson-core-2.8.8.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.3.9.RELEASE/95f5f5cf3cae64266a89dc1bc9e0484425cd8358/spring-aop-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.3.9.RELEASE/4edca6913da9e62a6586714e053e01a61952a153/spring-expression-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/net.minidev/json-smart/2.2.1/5b9e5df7a62d1279b70dc882b041d249c4f0b002/json-smart-2.2.1.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/2.1/87c0ea803b69252868d09308b4618f766f135a96/objenesis-2.1.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.vaadin.external.google/android-json/0.0.20131108.vaadin1/fa26d351fe62a6a17f5cda1287c1c6110dec413f/android-json-0.0.20131108.vaadin1.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/net.sf.jopt-simple/jopt-simple/5.0.3/cdd846cfc4e0f7eefafc02c0f5dce32b9303aa2a/jopt-simple-5.0.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.yammer.metrics/metrics-core/2.2.0/f82c035cfa786d3cbec362c38c22a5f5b1bc8724/metrics-core-2.2.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-library/2.11.8/ddd5a8bced249bedd86fb4578a39b9fb71480573/scala-library-2.11.8.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.101tec/zkclient/0.10/c54d4b5a5e89af75a80b6d5857400165ce5188d0/zkclient-0.10.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper/3.4.9/cbd9135689d6622a411e1e9b0ce880b502be5277/zookeeper-3.4.9.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.scala-lang.modules/scala-parser-combinators_2.11/1.0.4/7369d653bcfa95d321994660477a4d7e81d7f490/scala-parser-combinators_2.11-1.0.4.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.1.11/ccedfbacef4a6515d2983e3f89ed753d5d4fb665/logback-classic-1.1.11.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.25/f8c32b13ff142a513eeb5b6330b1588dcb2c0461/jcl-over-slf4j-1.7.25.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.25/af5364cd6679bfffb114f0dec8a157aaa283b76/jul-to-slf4j-1.7.25.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.slf4j/log4j-over-slf4j/1.7.25/a87bb47468f47ee7aabbd54f93e133d4215769c3/log4j-over-slf4j-1.7.25.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/net.minidev/accessors-smart/1.1/a527213f2fea112a04c9bdf0ec0264e34104cd08/accessors-smart-1.1.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.1.11/88b8df40340eed549fb07e2613879bf6b006704d/logback-core-1.1.11.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.ow2.asm/asm/5.0.3/dcc2193db20e19e1feca8b1240dbbc4e190824fa/asm-5.0.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.16/7999a63bfccbc7c247a9aea10d83d4272bd492c6/log4j-1.2.16.jar
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.library.path=/Users/kamtaprasadmishra/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.io.tmpdir=/var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.compiler=&lt;NA&gt;
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:os.name=Mac OS X
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:os.arch=x86_64
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:os.version=10.16
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:user.name=kamtaprasadmishra
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:user.home=/Users/kamtaprasadmishra
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:user.dir=/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer
2022-04-28 17:04:31 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-6878716762584306360/version-2 snapdir /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-7891059507428364698/version-2
2022-04-28 17:04:31 [Test worker] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port /127.0.0.1:0
2022-04-28 17:04:31 [Test worker] ERROR o.a.zookeeper.server.ZooKeeperServer - ZKShutdownHandler is not registered, so ZooKeeper server won't take any action on ERROR or SHUTDOWN server state changes
2022-04-28 17:04:31 [ZkClient-EventThread-20-127.0.0.1:50286] INFO  org.I0Itec.zkclient.ZkEventThread - Starting ZkClient event thread.
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=10.88.32.46
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_301
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_301.jdk/Contents/Home/jre
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer/build/classes/test:/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer/build/resources/test:/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer/build/classes/main:/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer/build/resources/main:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/0.10.2.0/c20571ff756fcf8f4a7f76fc7b23707a4c14a67d/kafka-clients-0.10.2.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/1.2.2.RELEASE/3b75bf653f8752b6f1a89a490ea101113cf1b655/spring-kafka-1.2.2.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/1.5.4.RELEASE/5d6c554f34b20dffcbdfc7edf9b80956e2dace/spring-boot-starter-web-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.google.guava/guava/20.0/89507701249388e1ed5ddcf8c41f4ce1be7831ef/guava-20.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/1.5.4.RELEASE/a764033c4be6e73310a6b12604a37c20d3bd0176/spring-boot-starter-test-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka-test/1.2.2.RELEASE/6a21241085c019ec48cd6e4448bc79ae26e04be2/spring-kafka-test-1.2.2.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/net.jpountz.lz4/lz4/1.3.0/c708bb2590c0652a642236ef45d9f99ff842a2ce/lz4-1.3.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.2.6/48d92871ca286a47f230feb375f0bbffa83b85f6/snappy-java-1.1.2.6.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.25/da76ca59f6a57ee3102f8f9bd9cee742973efa8a/slf4j-api-1.7.25.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.3.9.RELEASE/a8c3bc6271b67102bc192e530257d3347e8d7b93/spring-messaging-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.2.0.RELEASE/4e2b3ea37df07ef6fd905696f1aa5d50128c2782/spring-retry-1.2.0.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/0.10.2.0/32bc203617ebd2f0802c85b91bb241dbe72faa7f/kafka-clients-0.10.2.0-test.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/1.5.4.RELEASE/74d5aa641503ddd12833c82cc19b295f9f40e8fa/spring-boot-starter-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/1.5.4.RELEASE/d7e26f1d0e594bd1aab7da227649fc12c1958416/spring-boot-starter-tomcat-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/5.3.5.Final/622a9bcef2eed6d41b5b8e0662c36212009e375/hibernate-validator-5.3.5.Final.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.8.8/bf88c7b27e95cbadce4e7c316a56c3efffda8026/jackson-databind-2.8.8.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.3.9.RELEASE/91dae64c4280093ad5fb4736a10913c9233479c1/spring-web-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.3.9.RELEASE/ca80b4a00abc388d8046bf372099f35564371c47/spring-webmvc-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-test/1.5.4.RELEASE/a7a68089a6cf35db5587029e5c163466dadf7c5b/spring-boot-test-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-test-autoconfigure/1.5.4.RELEASE/5c751eb6cfa58c86ba4ffc4c3334faf4331d5385/spring-boot-test-autoconfigure-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.jayway.jsonpath/json-path/2.2.0/22290d17944bd239fabf5ac69005a60a7ecbbbcb/json-path-2.2.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/junit/junit/4.12/2973d150c0dc1fefe998f834810d68f278ea58ec/junit-4.12.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.assertj/assertj-core/2.6.0/b532c3fc4f66bcfee4989a3514f1cd56203a33ad/assertj-core-2.6.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.10.19/e8546f5bef4e061d8dd73895b4e8f40e3fe6effe/mockito-core-1.10.19.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-library/1.3/4785a3c21320980282f9f33d0d1264a69040538f/hamcrest-library-1.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.skyscreamer/jsonassert/1.4.0/9cdbb373a06f6513e51e8c545ee6a5e981463edb/jsonassert-1.4.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.3.9.RELEASE/430b7298bfb85d66fb61e19ca8f06231b911e9f5/spring-core-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.3.9.RELEASE/35bf4c38c9245f5baeeda4bea7c41f4f33c5daf3/spring-test-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.3.9.RELEASE/daa5abf3779c8cad1a2910e1ea08e4272489d8ae/spring-beans-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka_2.11/0.10.2.0/1340a7ab7db442bc00be7eac85c395555347e5f1/kafka_2.11-0.10.2.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka_2.11/0.10.2.0/6ccefda962770dcc94350288bd0b56be9e266395/kafka_2.11-0.10.2.0-test.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.3.9.RELEASE/a186823724f03b98becd5f93b1fa107fe6f7a7ff/spring-context-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.5.4.RELEASE/cf51bb0751c1362a417eb59824d27d2907780d2/spring-boot-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.5.4.RELEASE/5591fa7358d950f374532c7d92dccf113ebfa1bb/spring-boot-autoconfigure-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/1.5.4.RELEASE/6b4364cfee82890ce9a9c2c59066f3a6e525debd/spring-boot-starter-logging-1.5.4.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.17/7a27ea250c5130b2922b86dea63cbb1cc10a660c/snakeyaml-1.17.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/8.5.15/f197a93ae66212767b004fd93d7a1a8ea62bc3fa/tomcat-embed-core-8.5.15.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/8.5.15/e4000e5386056eeebb43bf71e7d30c58d2473166/tomcat-embed-el-8.5.15.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/8.5.15/a92b066b0ea9ee1cb05b7d5e4bfed4ad8898f741/tomcat-embed-websocket-8.5.15.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.1.0.Final/8613ae82954779d518631e05daa73a6a954817d5/validation-api-1.1.0.Final.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.1.Final/c46217ab74b532568c0ed31dc599db3048bd1b67/jboss-logging-3.3.1.Final.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.3.3/864c8e370a691e343210cc7c532fc198cee460d8/classmate-1.3.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.8.0/45b426f7796b741035581a176744d91090e2e6fb/jackson-annotations-2.8.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.8.8/d478fb6de45a7c3d2cad07c8ad70c7f0a797a020/jackson-core-2.8.8.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.3.9.RELEASE/95f5f5cf3cae64266a89dc1bc9e0484425cd8358/spring-aop-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.3.9.RELEASE/4edca6913da9e62a6586714e053e01a61952a153/spring-expression-4.3.9.RELEASE.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/net.minidev/json-smart/2.2.1/5b9e5df7a62d1279b70dc882b041d249c4f0b002/json-smart-2.2.1.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/2.1/87c0ea803b69252868d09308b4618f766f135a96/objenesis-2.1.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.vaadin.external.google/android-json/0.0.20131108.vaadin1/fa26d351fe62a6a17f5cda1287c1c6110dec413f/android-json-0.0.20131108.vaadin1.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/net.sf.jopt-simple/jopt-simple/5.0.3/cdd846cfc4e0f7eefafc02c0f5dce32b9303aa2a/jopt-simple-5.0.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.yammer.metrics/metrics-core/2.2.0/f82c035cfa786d3cbec362c38c22a5f5b1bc8724/metrics-core-2.2.0.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-library/2.11.8/ddd5a8bced249bedd86fb4578a39b9fb71480573/scala-library-2.11.8.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/com.101tec/zkclient/0.10/c54d4b5a5e89af75a80b6d5857400165ce5188d0/zkclient-0.10.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper/3.4.9/cbd9135689d6622a411e1e9b0ce880b502be5277/zookeeper-3.4.9.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.scala-lang.modules/scala-parser-combinators_2.11/1.0.4/7369d653bcfa95d321994660477a4d7e81d7f490/scala-parser-combinators_2.11-1.0.4.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.1.11/ccedfbacef4a6515d2983e3f89ed753d5d4fb665/logback-classic-1.1.11.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.25/f8c32b13ff142a513eeb5b6330b1588dcb2c0461/jcl-over-slf4j-1.7.25.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.25/af5364cd6679bfffb114f0dec8a157aaa283b76/jul-to-slf4j-1.7.25.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.slf4j/log4j-over-slf4j/1.7.25/a87bb47468f47ee7aabbd54f93e133d4215769c3/log4j-over-slf4j-1.7.25.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/net.minidev/accessors-smart/1.1/a527213f2fea112a04c9bdf0ec0264e34104cd08/accessors-smart-1.1.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.1.11/88b8df40340eed549fb07e2613879bf6b006704d/logback-core-1.1.11.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/org.ow2.asm/asm/5.0.3/dcc2193db20e19e1feca8b1240dbbc4e190824fa/asm-5.0.3.jar:/Users/kamtaprasadmishra/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.16/7999a63bfccbc7c247a9aea10d83d4272bd492c6/log4j-1.2.16.jar
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/kamtaprasadmishra/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=&lt;NA&gt;
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.16
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=kamtaprasadmishra
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/kamtaprasadmishra
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/kamtaprasadmishra/IdeaProjects/sample-spring-kafka-producer-consumer/sample-spring-kafka-producer
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=127.0.0.1:50286 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@5649b349
2022-04-28 17:04:32 [Test worker] INFO  org.I0Itec.zkclient.ZkClient - Waiting for keeper state SyncConnected
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server 127.0.0.1/127.0.0.1:50286. Will not attempt to authenticate using SASL (unknown error)
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to 127.0.0.1/127.0.0.1:50286, initiating session
2022-04-28 17:04:32 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:50292
2022-04-28 17:04:32 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:50292
2022-04-28 17:04:32 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2022-04-28 17:04:32 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x1806ff3832e0000 with negotiated timeout 6000 for client /127.0.0.1:50292
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server 127.0.0.1/127.0.0.1:50286, sessionid = 0x1806ff3832e0000, negotiated timeout = 6000
2022-04-28 17:04:32 [Test worker-EventThread] INFO  org.I0Itec.zkclient.ZkClient - zookeeper state changed (SyncConnected)
2022-04-28 17:04:32 [Test worker] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.10.2-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://localhost:50293
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.2-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 50293
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = 127.0.0.1:50286
	zookeeper.connection.timeout.ms = 10000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2022-04-28 17:04:32 [Test worker] INFO  kafka.server.KafkaServer - starting
2022-04-28 17:04:32 [Test worker] INFO  kafka.server.KafkaServer - Connecting to zookeeper on 127.0.0.1:50286
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=127.0.0.1:50286 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@194e7ae5
2022-04-28 17:04:32 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  org.I0Itec.zkclient.ZkEventThread - Starting ZkClient event thread.
2022-04-28 17:04:32 [Test worker] INFO  org.I0Itec.zkclient.ZkClient - Waiting for keeper state SyncConnected
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server 127.0.0.1/127.0.0.1:50286. Will not attempt to authenticate using SASL (unknown error)
2022-04-28 17:04:32 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:50294
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to 127.0.0.1/127.0.0.1:50286, initiating session
2022-04-28 17:04:32 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:50294
2022-04-28 17:04:32 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x1806ff3832e0001 with negotiated timeout 6000 for client /127.0.0.1:50294
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server 127.0.0.1/127.0.0.1:50286, sessionid = 0x1806ff3832e0001, negotiated timeout = 6000
2022-04-28 17:04:32 [Test worker-EventThread] INFO  org.I0Itec.zkclient.ZkClient - zookeeper state changed (SyncConnected)
2022-04-28 17:04:32 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x5 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2022-04-28 17:04:32 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xb zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2022-04-28 17:04:32 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x13 zxid:0xd txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2022-04-28 17:04:32 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x1b zxid:0x12 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2022-04-28 17:04:32 [Test worker] INFO  kafka.server.KafkaServer - Cluster ID = NrjQgbtvQxK2Y5XTasdXBw
2022-04-28 17:04:32 [Test worker] WARN  k.server.BrokerMetadataCheckpoint - No meta.properties file under dir /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291/meta.properties
2022-04-28 17:04:32 [ThrottledRequestReaper-Fetch] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Fetch], Starting 
2022-04-28 17:04:32 [ThrottledRequestReaper-Produce] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Produce], Starting 
2022-04-28 17:04:32 [Test worker] INFO  kafka.log.LogManager - Loading logs.
2022-04-28 17:04:32 [Test worker] INFO  kafka.log.LogManager - Logs loading complete in 7 ms.
2022-04-28 17:04:32 [Test worker] INFO  kafka.log.LogManager - Starting log cleanup with a period of 300000 ms.
2022-04-28 17:04:32 [Test worker] INFO  kafka.log.LogManager - Starting log flusher with a default period of 9223372036854775807 ms.
2022-04-28 17:04:32 [Test worker] INFO  kafka.log.LogCleaner - Starting the log cleaner
2022-04-28 17:04:32 [kafka-log-cleaner-thread-0] INFO  kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Starting 
2022-04-28 17:04:32 [Test worker] INFO  kafka.network.Acceptor - Awaiting socket connections on localhost:50293.
2022-04-28 17:04:32 [Test worker] INFO  kafka.network.SocketServer - [Socket Server on Broker 0], Started 1 acceptor threads
2022-04-28 17:04:32 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Starting 
2022-04-28 17:04:32 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Starting 
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Controller starting up
2022-04-28 17:04:32 [Test worker] INFO  kafka.utils.ZKCheckedEphemeral - Creating /controller (is it secure? false)
2022-04-28 17:04:32 [Test worker] INFO  kafka.utils.ZKCheckedEphemeral - Result of znode creation is: OK
2022-04-28 17:04:32 [Test worker] INFO  kafka.server.ZookeeperLeaderElector - 0 successfully elected as leader
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Broker 0 starting become controller state transition
2022-04-28 17:04:32 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:setData cxid:0x25 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Controller 0 incremented epoch to 1
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Partitions undergoing preferred replica election: 
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Partitions that completed preferred replica election: 
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Resuming preferred replica election for partitions: 
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Partitions being reassigned: Map()
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Partitions already reassigned: Set()
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Resuming reassignment of partitions: Map()
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: List of topics to be deleted: 
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: List of topics ineligible for deletion: 
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Currently active brokers in the cluster: Set()
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Currently shutting brokers in the cluster: Set()
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Current list of topics in the cluster: Set()
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 0]: Started replica state machine with initial state -&gt; Map()
2022-04-28 17:04:32 [Test worker] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 0]: Started partition state machine with initial state -&gt; Map()
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Broker 0 is ready to serve as the new controller with epoch 1
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Starting preferred replica leader election for partitions 
2022-04-28 17:04:32 [Test worker] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions 
2022-04-28 17:04:32 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:delete cxid:0x36 zxid:0x18 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: starting the partition rebalance scheduler
2022-04-28 17:04:32 [delete-topics-thread-0] INFO  k.c.TopicDeletionManager$DeleteTopicsThread - [delete-topics-thread-0], Starting 
2022-04-28 17:04:32 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Controller startup complete
2022-04-28 17:04:32 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Starting 
2022-04-28 17:04:32 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Starting 
2022-04-28 17:04:32 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Starting 
2022-04-28 17:04:32 [Test worker] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 0]: Starting up.
2022-04-28 17:04:32 [Test worker] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 0]: Startup complete.
2022-04-28 17:04:32 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds.
2022-04-28 17:04:32 [Test worker] INFO  kafka.utils.Mx4jLoader$ - Will not load MX4J, mx4j-tools.jar is not in the classpath
2022-04-28 17:04:32 [Test worker] INFO  kafka.utils.ZKCheckedEphemeral - Creating /brokers/ids/0 (is it secure? false)
2022-04-28 17:04:32 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x41 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2022-04-28 17:04:32 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2022-04-28 17:04:32 [Test worker] INFO  kafka.utils.ZKCheckedEphemeral - Result of znode creation is: OK
2022-04-28 17:04:32 [Test worker] INFO  kafka.utils.ZkUtils - Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(localhost,50293,ListenerName(PLAINTEXT),PLAINTEXT)
2022-04-28 17:04:32 [Test worker] WARN  k.server.BrokerMetadataCheckpoint - No meta.properties file under dir /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291/meta.properties
2022-04-28 17:04:32 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.s.ZookeeperLeaderElector$LeaderChangeListener - New leader is 0
2022-04-28 17:04:32 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.c.ReplicaStateMachine$BrokerChangeListener - [BrokerChangeListener on Controller 0]: Broker change listener fired for path /brokers/ids with children 0
2022-04-28 17:04:32 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.2.0
2022-04-28 17:04:32 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 576d93a8dc0cf421
2022-04-28 17:04:32 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 0], started
2022-04-28 17:04:32 [Test worker] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.10.2-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://localhost:50296
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.2-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 50296
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = 127.0.0.1:50286
	zookeeper.connection.timeout.ms = 10000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2022-04-28 17:04:32 [Test worker] INFO  kafka.server.KafkaServer - starting
2022-04-28 17:04:32 [Test worker] INFO  kafka.server.KafkaServer - Connecting to zookeeper on 127.0.0.1:50286
2022-04-28 17:04:32 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=127.0.0.1:50286 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@7bdadee5
2022-04-28 17:04:32 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  org.I0Itec.zkclient.ZkEventThread - Starting ZkClient event thread.
2022-04-28 17:04:32 [Test worker] INFO  org.I0Itec.zkclient.ZkClient - Waiting for keeper state SyncConnected
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server 127.0.0.1/127.0.0.1:50286. Will not attempt to authenticate using SASL (unknown error)
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to 127.0.0.1/127.0.0.1:50286, initiating session
2022-04-28 17:04:32 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:50297
2022-04-28 17:04:32 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:50297
2022-04-28 17:04:32 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x1806ff3832e0002 with negotiated timeout 6000 for client /127.0.0.1:50297
2022-04-28 17:04:32 [Test worker-SendThread(127.0.0.1:50286)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server 127.0.0.1/127.0.0.1:50286, sessionid = 0x1806ff3832e0002, negotiated timeout = 6000
2022-04-28 17:04:32 [Test worker-EventThread] INFO  org.I0Itec.zkclient.ZkClient - zookeeper state changed (SyncConnected)
2022-04-28 17:04:33 [Test worker] INFO  kafka.server.KafkaServer - Cluster ID = NrjQgbtvQxK2Y5XTasdXBw
2022-04-28 17:04:33 [Test worker] WARN  k.server.BrokerMetadataCheckpoint - No meta.properties file under dir /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163/meta.properties
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.c.ReplicaStateMachine$BrokerChangeListener - [BrokerChangeListener on Controller 0]: Newly added brokers: 0, deleted brokers: , all live brokers: 0
2022-04-28 17:04:33 [ThrottledRequestReaper-Fetch] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Fetch], Starting 
2022-04-28 17:04:33 [ThrottledRequestReaper-Produce] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Produce], Starting 
2022-04-28 17:04:33 [Test worker] INFO  kafka.log.LogManager - Loading logs.
2022-04-28 17:04:33 [Test worker] INFO  kafka.log.LogManager - Logs loading complete in 1 ms.
2022-04-28 17:04:33 [Test worker] INFO  kafka.log.LogManager - Starting log cleanup with a period of 300000 ms.
2022-04-28 17:04:33 [Test worker] INFO  kafka.log.LogManager - Starting log flusher with a default period of 9223372036854775807 ms.
2022-04-28 17:04:33 [Test worker] INFO  kafka.log.LogCleaner - Starting the log cleaner
2022-04-28 17:04:33 [kafka-log-cleaner-thread-0] INFO  kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Starting 
2022-04-28 17:04:33 [Controller-0-to-broker-0-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-0-send-thread], Starting 
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 0]: New broker startup callback for 0
2022-04-28 17:04:33 [Test worker] INFO  kafka.network.Acceptor - Awaiting socket connections on localhost:50296.
2022-04-28 17:04:33 [Test worker] INFO  kafka.network.SocketServer - [Socket Server on Broker 1], Started 1 acceptor threads
2022-04-28 17:04:33 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Starting 
2022-04-28 17:04:33 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Starting 
2022-04-28 17:04:33 [Controller-0-to-broker-0-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-0-send-thread], Controller 0 connected to localhost:50293 (id: 0 rack: null) for sending state change requests
2022-04-28 17:04:33 [Test worker] INFO  kafka.controller.KafkaController - [Controller 1]: Controller starting up
2022-04-28 17:04:33 [Test worker] INFO  kafka.controller.KafkaController - [Controller 1]: Controller startup complete
2022-04-28 17:04:33 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Starting 
2022-04-28 17:04:33 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Starting 
2022-04-28 17:04:33 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Starting 
2022-04-28 17:04:33 [Test worker] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Starting up.
2022-04-28 17:04:33 [Test worker] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Startup complete.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds.
2022-04-28 17:04:33 [Test worker] INFO  kafka.utils.Mx4jLoader$ - Will not load MX4J, mx4j-tools.jar is not in the classpath
2022-04-28 17:04:33 [Test worker] INFO  kafka.utils.ZKCheckedEphemeral - Creating /brokers/ids/1 (is it secure? false)
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0002 type:create cxid:0x18 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0002 type:create cxid:0x19 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2022-04-28 17:04:33 [Test worker] INFO  kafka.utils.ZKCheckedEphemeral - Result of znode creation is: OK
2022-04-28 17:04:33 [Test worker] INFO  kafka.utils.ZkUtils - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,50296,ListenerName(PLAINTEXT),PLAINTEXT)
2022-04-28 17:04:33 [Test worker] WARN  k.server.BrokerMetadataCheckpoint - No meta.properties file under dir /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163/meta.properties
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.c.ReplicaStateMachine$BrokerChangeListener - [BrokerChangeListener on Controller 0]: Broker change listener fired for path /brokers/ids with children 0,1
2022-04-28 17:04:33 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.2.0
2022-04-28 17:04:33 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 576d93a8dc0cf421
2022-04-28 17:04:33 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], started
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.c.ReplicaStateMachine$BrokerChangeListener - [BrokerChangeListener on Controller 0]: Newly added brokers: 1, deleted brokers: , all live brokers: 0,1
2022-04-28 17:04:33 [Controller-0-to-broker-1-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-1-send-thread], Starting 
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 0]: New broker startup callback for 1
2022-04-28 17:04:33 [Controller-0-to-broker-1-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-1-send-thread], Controller 0 connected to localhost:50296 (id: 1 rack: null) for sending state change requests
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0000 type:setData cxid:0x5 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/messages Error:KeeperErrorCode = NoNode for /config/topics/messages
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0000 type:create cxid:0x6 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2022-04-28 17:04:33 [Test worker] INFO  kafka.admin.AdminUtils$ - Topic creation {&quot;version&quot;:1,&quot;partitions&quot;:{&quot;1&quot;:[1,0],&quot;0&quot;:[0,1]}}
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.c.PartitionStateMachine$TopicChangeListener - [TopicChangeListener on Controller 0]: New topics: [Set(messages)], deleted topics: [Set()], new partition replica assignment [Map([messages,1] -&gt; List(1, 0), [messages,0] -&gt; List(0, 1))]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 0]: New topic creation callback for [messages,1],[messages,0]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 0]: New partition creation callback for [messages,1],[messages,0]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [messages,1],[messages,0]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=messages,Partition=1,Replica=1],[Topic=messages,Partition=1,Replica=0],[Topic=messages,Partition=0,Replica=0],[Topic=messages,Partition=0,Replica=1]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [messages,1],[messages,0]
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x53 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/brokers/topics/messages/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/messages/partitions/1
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x54 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/brokers/topics/messages/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/messages/partitions
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x58 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/messages/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/messages/partitions/0
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=messages,Partition=1,Replica=1],[Topic=messages,Partition=1,Replica=0],[Topic=messages,Partition=0,Replica=0],[Topic=messages,Partition=0,Replica=1]
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions messages-0
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions messages-1
2022-04-28 17:04:33 [Test worker] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:50293, 127.0.0.1:50296]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sampleConsumer
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-04-28 17:04:33 [Test worker] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:50293, 127.0.0.1:50296]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sampleConsumer
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.log.Log - Completed load of log messages-0 with 1 log segments and log end offset 0 in 18 ms
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.log.Log - Completed load of log messages-1 with 1 log segments and log end offset 0 in 18 ms
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.log.LogManager - Created log for partition [messages,0] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; [delete], flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 1073741824, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.log.LogManager - Created log for partition [messages,1] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; [delete], flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 1073741824, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.cluster.Partition - Partition [messages,0] on broker 0: No checkpointed highwatermark is found for partition messages-0
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.cluster.Partition - Partition [messages,1] on broker 1: No checkpointed highwatermark is found for partition messages-1
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.log.Log - Completed load of log messages-1 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.log.Log - Completed load of log messages-0 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.log.LogManager - Created log for partition [messages,0] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; [delete], flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 1073741824, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.log.LogManager - Created log for partition [messages,1] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; [delete], flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 1073741824, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.2.0
2022-04-28 17:04:33 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 576d93a8dc0cf421
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.cluster.Partition - Partition [messages,0] on broker 1: No checkpointed highwatermark is found for partition messages-0
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.cluster.Partition - Partition [messages,1] on broker 0: No checkpointed highwatermark is found for partition messages-1
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions messages-1
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions messages-0
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.log.Log - Truncating log messages-1 to offset 0.
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.log.Log - Truncating log messages-0 to offset 0.
2022-04-28 17:04:33 [Test worker] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:50293, 127.0.0.1:50296]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-04-28 17:04:33 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.2.0
2022-04-28 17:04:33 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 576d93a8dc0cf421
2022-04-28 17:04:33 [sampleConsumer-C-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 3 : {messages=LEADER_NOT_AVAILABLE}
2022-04-28 17:04:33 [ReplicaFetcherThread-0-1] INFO  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-1], Starting 
2022-04-28 17:04:33 [ReplicaFetcherThread-0-0] INFO  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-0], Starting 
2022-04-28 17:04:33 [kafka-request-handler-1] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([messages-0, initOffset 0 to broker BrokerEndPoint(0,localhost,50293)] )
2022-04-28 17:04:33 [kafka-request-handler-2] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([messages-1, initOffset 0 to broker BrokerEndPoint(1,localhost,50296)] )
2022-04-28 17:04:33 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {messages=LEADER_NOT_AVAILABLE}
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:setData cxid:0x66 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x67 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.admin.AdminUtils$ - Topic creation {&quot;version&quot;:1,&quot;partitions&quot;:{&quot;45&quot;:[0],&quot;34&quot;:[1],&quot;12&quot;:[1],&quot;8&quot;:[1],&quot;19&quot;:[0],&quot;23&quot;:[0],&quot;4&quot;:[1],&quot;40&quot;:[1],&quot;15&quot;:[0],&quot;11&quot;:[0],&quot;9&quot;:[0],&quot;44&quot;:[1],&quot;33&quot;:[0],&quot;22&quot;:[1],&quot;26&quot;:[1],&quot;37&quot;:[0],&quot;13&quot;:[0],&quot;46&quot;:[1],&quot;24&quot;:[1],&quot;35&quot;:[0],&quot;16&quot;:[1],&quot;5&quot;:[0],&quot;10&quot;:[1],&quot;48&quot;:[1],&quot;21&quot;:[0],&quot;43&quot;:[0],&quot;32&quot;:[1],&quot;49&quot;:[0],&quot;6&quot;:[1],&quot;36&quot;:[1],&quot;1&quot;:[0],&quot;39&quot;:[0],&quot;17&quot;:[0],&quot;25&quot;:[0],&quot;14&quot;:[1],&quot;47&quot;:[0],&quot;31&quot;:[0],&quot;42&quot;:[1],&quot;0&quot;:[1],&quot;20&quot;:[1],&quot;27&quot;:[0],&quot;2&quot;:[1],&quot;38&quot;:[1],&quot;18&quot;:[1],&quot;30&quot;:[1],&quot;7&quot;:[0],&quot;29&quot;:[0],&quot;41&quot;:[0],&quot;3&quot;:[0],&quot;28&quot;:[1]}}
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.server.KafkaApis - [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2022-04-28 17:04:33 [ReplicaFetcherThread-0-1] ERROR kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-1], Error for partition [messages,1] to broker 1:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2022-04-28 17:04:33 [ReplicaFetcherThread-0-0] ERROR kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-0], Error for partition [messages,0] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.c.PartitionStateMachine$TopicChangeListener - [TopicChangeListener on Controller 0]: New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map([__consumer_offsets,19] -&gt; List(0), [__consumer_offsets,30] -&gt; List(1), [__consumer_offsets,47] -&gt; List(0), [__consumer_offsets,29] -&gt; List(0), [__consumer_offsets,41] -&gt; List(0), [__consumer_offsets,39] -&gt; List(0), [__consumer_offsets,10] -&gt; List(1), [__consumer_offsets,17] -&gt; List(0), [__consumer_offsets,14] -&gt; List(1), [__consumer_offsets,40] -&gt; List(1), [__consumer_offsets,18] -&gt; List(1), [__consumer_offsets,26] -&gt; List(1), [__consumer_offsets,0] -&gt; List(1), [__consumer_offsets,24] -&gt; List(1), [__consumer_offsets,33] -&gt; List(0), [__consumer_offsets,20] -&gt; List(1), [__consumer_offsets,21] -&gt; List(0), [__consumer_offsets,3] -&gt; List(0), [__consumer_offsets,5] -&gt; List(0), [__consumer_offsets,22] -&gt; List(1), [__consumer_offsets,12] -&gt; List(1), [__consumer_offsets,8] -&gt; List(1), [__consumer_offsets,23] -&gt; List(0), [__consumer_offsets,15] -&gt; List(0), [__consumer_offsets,48] -&gt; List(1), [__consumer_offsets,11] -&gt; List(0), [__consumer_offsets,13] -&gt; List(0), [__consumer_offsets,49] -&gt; List(0), [__consumer_offsets,6] -&gt; List(1), [__consumer_offsets,28] -&gt; List(1), [__consumer_offsets,4] -&gt; List(1), [__consumer_offsets,37] -&gt; List(0), [__consumer_offsets,31] -&gt; List(0), [__consumer_offsets,44] -&gt; List(1), [__consumer_offsets,42] -&gt; List(1), [__consumer_offsets,34] -&gt; List(1), [__consumer_offsets,46] -&gt; List(1), [__consumer_offsets,25] -&gt; List(0), [__consumer_offsets,45] -&gt; List(0), [__consumer_offsets,27] -&gt; List(0), [__consumer_offsets,32] -&gt; List(1), [__consumer_offsets,43] -&gt; List(0), [__consumer_offsets,36] -&gt; List(1), [__consumer_offsets,35] -&gt; List(0), [__consumer_offsets,7] -&gt; List(0), [__consumer_offsets,9] -&gt; List(0), [__consumer_offsets,38] -&gt; List(1), [__consumer_offsets,1] -&gt; List(0), [__consumer_offsets,16] -&gt; List(1), [__consumer_offsets,2] -&gt; List(1))]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 0]: New topic creation callback for [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 0]: New partition creation callback for [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=1]
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xa0 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xa1 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xa5 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xa8 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xab zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xae zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xb1 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xb4 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xb7 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xba zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xbd zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xc0 zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xc3 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xc6 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xc9 zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xcc zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xcf zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xd2 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xd5 zxid:0x65 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xda zxid:0x68 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xdd zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xe1 zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xe5 zxid:0x71 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xe8 zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xeb zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xee zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xf1 zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xf4 zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xf7 zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xfa zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0xfd zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x100 zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x103 zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x106 zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x109 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x10c zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x10f zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x112 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x115 zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x118 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x11b zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x11e zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x121 zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x124 zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x127 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x12a zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x12d zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x130 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x133 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x136 zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2022-04-28 17:04:33 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0001 type:create cxid:0x139 zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2022-04-28 17:04:33 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=1]
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-21,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-31,__consumer_offsets-3,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-17,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-43,__consumer_offsets-39,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-29
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-4,__consumer_offsets-46,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-18,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-48,__consumer_offsets-2,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-12,__consumer_offsets-26,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-29 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,29] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-0 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,0] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-29
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,0] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-0
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-45 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,45] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-45
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-48 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,48] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,48] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-48
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-7 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,7] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-10 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-7
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,10] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,10] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-10
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-23 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-26 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,23] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,26] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-23
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,26] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-26
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-42 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-39 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,42] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,42] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-42
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,39] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-39
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-4 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-1 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,4] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,4] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-4
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,1] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-1
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-20 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,20] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-17 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,20] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-20
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,17] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-17
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-36 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,36] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,36] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-36
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-33 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,33] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-33
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-14 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,14] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,14] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-14
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-49 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,49] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-49
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-30 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,30] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,30] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-30
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-11 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,11] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-11
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-46 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-27 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,46] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,46] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-46
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,27] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-27
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-8 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-43 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,8] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,43] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,8] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-8
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-43
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-24 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,24] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,24] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-24
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-5 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,5] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-5
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-40 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,40] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,40] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-40
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-21 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,21] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-21
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-2 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,2] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,2] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-2
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-37 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,37] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-37
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-18 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,18] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,18] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-18
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-15 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,15] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-15
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-34 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,34] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-31 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,34] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-34
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,31] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-31
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-12 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,12] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,12] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-12
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-47 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,47] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-47
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-28 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,28] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,28] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-28
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-9 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,9] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-9
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-38 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,38] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-19 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,38] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-38
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,19] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-19
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-44 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-35 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,44] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,44] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-44
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,35] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-35
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-6 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,6] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,6] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-6
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-25 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,25] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-25
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-16 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,16] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,16] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-16
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-41 with 1 log segments and log end offset 0 in 3 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,41] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-22 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-41
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,22] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,22] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-22
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-3 with 1 log segments and log end offset 0 in 1 ms
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.Log - Completed load of log __consumer_offsets-32 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,3] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-3
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,32] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-986385624897876163 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-3] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,32] on broker 1: No checkpointed highwatermark is found for partition __consumer_offsets-32
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-22
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.Log - Completed load of log __consumer_offsets-13 with 1 log segments and log end offset 0 in 2 ms
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.log.LogManager - Created log for partition [__consumer_offsets,13] in /var/folders/c9/y55p8t516v7_m5bkc5z7xsym0000gq/T/kafka-1386851894318524291 with properties {compression.type -&gt; producer, message.format.version -&gt; 0.10.2-IV0, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; true, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; compact, flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 104857600, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}.
2022-04-28 17:04:33 [kafka-request-handler-5] INFO  kafka.cluster.Partition - Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-13
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-25
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-25 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-22 in 5 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-28
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-31
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-31 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-28 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-37
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-34
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-37 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-34 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-43
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-40
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-43 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-40 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-5
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-2
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-2 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-5 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-46
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-49
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-49 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-11
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-46 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-8
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-11 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-17
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-8 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-14
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-17 in 0 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-23
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-23 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-14 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-29
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-20
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-29 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-20 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-35
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-26
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-26 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-35 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-32
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-41
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-41 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-3
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-32 in 10 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-38
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-3 in 10 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-47
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-47 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-38 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-0
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-9
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-0 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-9 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-44
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-15
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-44 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-15 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-6
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-21
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-6 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-21 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-12
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-27
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-12 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-27 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-18
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-33
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-18 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-33 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-24
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-39
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-24 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-39 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-30
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-1
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-30 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-36
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-1 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-45
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-36 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-45 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-42
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-7
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-42 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-7 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-4
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-13
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-4 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-13 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-48
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-19
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-48 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-19 in 2 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-10
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-10 in 1 milliseconds.
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from __consumer_offsets-16
2022-04-28 17:04:33 [group-metadata-manager-0] INFO  k.coordinator.GroupMetadataManager - [Group Metadata Manager on Broker 1]: Finished loading offsets from __consumer_offsets-16 in 3 milliseconds.
2022-04-28 17:04:33 [sampleConsumer-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator localhost:50296 (id: 2147483646 rack: null) for group sampleConsumer.
2022-04-28 17:04:33 [sampleConsumer-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group sampleConsumer
2022-04-28 17:04:33 [sampleConsumer-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer - partitions revoked:[]
2022-04-28 17:04:33 [sampleConsumer-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group sampleConsumer
2022-04-28 17:04:33 [kafka-request-handler-4] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Preparing to restabilize group sampleConsumer with old generation 0
2022-04-28 17:04:33 [kafka-request-handler-4] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Stabilized group sampleConsumer generation 1
2022-04-28 17:04:33 [kafka-request-handler-6] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Assignment received from leader for group sampleConsumer for generation 1
2022-04-28 17:04:33 [sampleConsumer-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group sampleConsumer with generation 1
2022-04-28 17:04:33 [sampleConsumer-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [messages-0, messages-1] for group sampleConsumer
2022-04-28 17:04:33 [sampleConsumer-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer - partitions assigned:[messages-0, messages-1]
2022-04-28 17:04:34 [sampleConsumer-L-1] INFO  sample.producer.embed.EmbedKafkaTest - Receiving: ConsumerRecord(topic = messages, partition = 0, offset = 0, CreateTime = 1651145673322, checksum = 2728622047, serialized key size = 4, serialized value size = 8, key = 0, value = message1)
2022-04-28 17:04:34 [sampleConsumer-L-1] INFO  sample.producer.embed.EmbedKafkaTest - Receiving: ConsumerRecord(topic = messages, partition = 0, offset = 1, CreateTime = 1651145673328, checksum = 1827595527, serialized key size = 4, serialized value size = 8, key = 1, value = message2)
2022-04-28 17:04:34 [sampleConsumer-L-1] INFO  sample.producer.embed.EmbedKafkaTest - Receiving: ConsumerRecord(topic = messages, partition = 1, offset = 0, CreateTime = 1651145673328, checksum = 2787359071, serialized key size = 4, serialized value size = 8, key = 2, value = message3)
2022-04-28 17:04:34 [sampleConsumer-L-1] INFO  sample.producer.embed.EmbedKafkaTest - Receiving: ConsumerRecord(topic = messages, partition = 1, offset = 1, CreateTime = 1651145673329, checksum = 2047571687, serialized key size = 4, serialized value size = 8, key = 3, value = message4)
2022-04-28 17:04:36 [kafka-request-handler-2] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Preparing to restabilize group sampleConsumer with old generation 1
2022-04-28 17:04:36 [kafka-request-handler-2] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Group sampleConsumer with generation 2 is now empty
2022-04-28 17:04:36 [sampleConsumer-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
2022-04-28 17:04:36 [Test worker] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:50293, 127.0.0.1:50296]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-04-28 17:04:36 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.2.0
2022-04-28 17:04:36 [Test worker] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 576d93a8dc0cf421
2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:50293, 127.0.0.1:50296]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sampleRawConsumer
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:50293, 127.0.0.1:50296]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sampleRawConsumer
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.2.0
2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 576d93a8dc0cf421
2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator localhost:50296 (id: 2147483646 rack: null) for group sampleRawConsumer.
2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group sampleRawConsumer
2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group sampleRawConsumer
2022-04-28 17:04:36 [kafka-request-handler-4] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Preparing to restabilize group sampleRawConsumer with old generation 0
2022-04-28 17:04:36 [kafka-request-handler-4] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Stabilized group sampleRawConsumer generation 1
2022-04-28 17:04:36 [kafka-request-handler-6] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Assignment received from leader for group sampleRawConsumer for generation 1
2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group sampleRawConsumer with generation 1
2022-04-28 17:04:36 [pool-10-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [messages-0, messages-1] for group sampleRawConsumer
2022-04-28 17:04:36 [pool-10-thread-1] INFO  sample.producer.embed.EmbedKafkaTest - consuming from topic = messages, partition = 0, offset = 0, key = 0, value = message1
2022-04-28 17:04:36 [pool-10-thread-1] INFO  sample.producer.embed.EmbedKafkaTest - consuming from topic = messages, partition = 0, offset = 1, key = 1, value = message2
2022-04-28 17:04:36 [pool-10-thread-1] INFO  sample.producer.embed.EmbedKafkaTest - consuming from topic = messages, partition = 0, offset = 2, key = 0, value = message0
2022-04-28 17:04:36 [pool-10-thread-1] INFO  sample.producer.embed.EmbedKafkaTest - consuming from topic = messages, partition = 0, offset = 3, key = 1, value = message1
2022-04-28 17:04:36 [pool-10-thread-1] INFO  sample.producer.embed.EmbedKafkaTest - consuming from topic = messages, partition = 1, offset = 0, key = 2, value = message3
2022-04-28 17:04:36 [pool-10-thread-1] INFO  sample.producer.embed.EmbedKafkaTest - consuming from topic = messages, partition = 1, offset = 1, key = 3, value = message4
2022-04-28 17:04:36 [pool-10-thread-1] INFO  sample.producer.embed.EmbedKafkaTest - consuming from topic = messages, partition = 1, offset = 2, key = 2, value = message2
2022-04-28 17:04:36 [pool-10-thread-1] INFO  sample.producer.embed.EmbedKafkaTest - consuming from topic = messages, partition = 1, offset = 3, key = 3, value = message3
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 0], shutting down
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 0], Starting controlled shutdown
2022-04-28 17:04:36 [kafka-request-handler-1] INFO  kafka.controller.KafkaController - [Controller 0]: Shutting down broker 0
2022-04-28 17:04:36 [kafka-request-handler-1] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 0]: Invoking state change to OfflineReplica for replicas [Topic=messages,Partition=1,Replica=0]
2022-04-28 17:04:36 [kafka-request-handler-7] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions messages-1
2022-04-28 17:04:36 [kafka-request-handler-7] INFO  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-1], Shutting down
2022-04-28 17:04:36 [kafka-request-handler-1] INFO  kafka.controller.KafkaController - [Controller 0]: New leader and ISR for partition [messages,1] is {&quot;leader&quot;:1,&quot;leader_epoch&quot;:1,&quot;isr&quot;:[1]}
2022-04-28 17:04:36 [kafka-request-handler-1] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [messages,0]
2022-04-28 17:04:36 [kafka-request-handler-1] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions messages-1
2022-04-28 17:04:36 [kafka-request-handler-1] INFO  state.change.logger - Broker 1 skipped the become-leader state change after marking its partition as leader with correlation id 5 from controller 0 epoch 1 for partition messages-1 since it is already the leader for the partition.
2022-04-28 17:04:36 [kafka-request-handler-6] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions messages-0
2022-04-28 17:04:36 [kafka-request-handler-6] INFO  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-0], Shutting down
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 0], Controlled shutdown succeeded
2022-04-28 17:04:36 [Test worker] INFO  kafka.network.SocketServer - [Socket Server on Broker 0], Shutting down
2022-04-28 17:04:36 [ReplicaFetcherThread-0-0] INFO  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-0], Stopped 
2022-04-28 17:04:36 [kafka-request-handler-6] INFO  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-0], Shutdown completed
2022-04-28 17:04:36 [Test worker] INFO  kafka.network.SocketServer - [Socket Server on Broker 0], Shutdown completed
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.KafkaRequestHandlerPool - [Kafka Request Handler on Broker 0], shutting down
2022-04-28 17:04:36 [Controller-0-to-broker-0-send-thread] WARN  kafka.controller.RequestSendThread - [Controller-0-to-broker-0-send-thread], Controller 0 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=0, controllerEpoch=1, deletePartitions=false, partitions=messages-1) to broker localhost:50293 (id: 0 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 0 was disconnected before the response was read
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:114)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1$$anonfun$apply$1.apply(NetworkClientBlockingOps.scala:112)
	at scala.Option.foreach(Option.scala:257)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:112)
	at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingSendAndReceive$extension$1.apply(NetworkClientBlockingOps.scala:108)
	at kafka.utils.NetworkClientBlockingOps$.recursivePoll$1(NetworkClientBlockingOps.scala:136)
	at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollContinuously$extension(NetworkClientBlockingOps.scala:142)
	at kafka.utils.NetworkClientBlockingOps$.blockingSendAndReceive$extension(NetworkClientBlockingOps.scala:108)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:192)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:184)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
2022-04-28 17:04:36 [ReplicaFetcherThread-0-1] INFO  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-1], Stopped 
2022-04-28 17:04:36 [kafka-request-handler-7] INFO  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-0-1], Shutdown completed
2022-04-28 17:04:36 [kafka-request-handler-3] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions messages-1
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.KafkaRequestHandlerPool - [Kafka Request Handler on Broker 0], shut down completely
2022-04-28 17:04:36 [Test worker] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Fetch], Shutting down
2022-04-28 17:04:36 [ThrottledRequestReaper-Fetch] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Fetch], Stopped 
2022-04-28 17:04:36 [Test worker] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Fetch], Shutdown completed
2022-04-28 17:04:36 [Test worker] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Produce], Shutting down
2022-04-28 17:04:36 [ThrottledRequestReaper-Produce] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Produce], Stopped 
2022-04-28 17:04:36 [Test worker] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Produce], Shutdown completed
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.KafkaApis - [KafkaApi-0] Shutdown complete.
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.ReplicaManager - [Replica Manager on Broker 0]: Shutting down
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] shutting down
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] shutdown completed
2022-04-28 17:04:36 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutting down
2022-04-28 17:04:36 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Stopped 
2022-04-28 17:04:36 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutdown completed
2022-04-28 17:04:36 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutting down
2022-04-28 17:04:36 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Stopped 
2022-04-28 17:04:36 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutdown completed
2022-04-28 17:04:36 [Test worker] INFO  kafka.server.ReplicaManager - [Replica Manager on Broker 0]: Shut down completely
2022-04-28 17:04:36 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutting down
2022-04-28 17:04:36 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutdown completed
2022-04-28 17:04:36 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Stopped 
2022-04-28 17:04:36 [Test worker] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 0]: Shutting down.
2022-04-28 17:04:36 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutting down
2022-04-28 17:04:37 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutdown completed
2022-04-28 17:04:37 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Stopped 
2022-04-28 17:04:37 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutting down
2022-04-28 17:04:37 [Controller-0-to-broker-0-send-thread] WARN  kafka.controller.RequestSendThread - [Controller-0-to-broker-0-send-thread], Controller 0's connection to broker localhost:50293 (id: 0 rack: null) was unsuccessful
java.net.SocketTimeoutException: Failed to connect within 1000 ms
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:233)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:185)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:184)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
2022-04-28 17:04:37 [ExpirationReaper-0] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Stopped 
2022-04-28 17:04:37 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0], Shutdown completed
2022-04-28 17:04:37 [Test worker] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 0]: Shutdown complete.
2022-04-28 17:04:37 [Test worker] INFO  kafka.log.LogManager - Shutting down.
2022-04-28 17:04:37 [Test worker] INFO  kafka.log.LogCleaner - Shutting down the log cleaner.
2022-04-28 17:04:37 [Test worker] INFO  kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Shutting down
2022-04-28 17:04:37 [kafka-log-cleaner-thread-0] INFO  kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Stopped 
2022-04-28 17:04:37 [Test worker] INFO  kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Shutdown completed
2022-04-28 17:04:37 [Test worker] INFO  kafka.log.LogManager - Shutdown complete.
2022-04-28 17:04:37 [Test worker] INFO  k.c.TopicDeletionManager$DeleteTopicsThread - [delete-topics-thread-0], Shutting down
2022-04-28 17:04:37 [delete-topics-thread-0] INFO  k.c.TopicDeletionManager$DeleteTopicsThread - [delete-topics-thread-0], Stopped 
2022-04-28 17:04:37 [Test worker] INFO  k.c.TopicDeletionManager$DeleteTopicsThread - [delete-topics-thread-0], Shutdown completed
2022-04-28 17:04:37 [Test worker] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 0]: Stopped partition state machine
2022-04-28 17:04:37 [Test worker] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 0]: Stopped replica state machine
2022-04-28 17:04:37 [Test worker] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-1-send-thread], Shutting down
2022-04-28 17:04:37 [Controller-0-to-broker-1-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-1-send-thread], Stopped 
2022-04-28 17:04:37 [Test worker] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-1-send-thread], Shutdown completed
2022-04-28 17:04:38 [Controller-0-to-broker-0-send-thread] WARN  kafka.controller.RequestSendThread - [Controller-0-to-broker-0-send-thread], Controller 0's connection to broker localhost:50293 (id: 0 rack: null) was unsuccessful
java.net.SocketTimeoutException: Failed to connect within 1000 ms
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:233)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:185)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:184)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
2022-04-28 17:04:38 [Test worker] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-0-send-thread], Shutting down
2022-04-28 17:04:38 [Controller-0-to-broker-0-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-0-send-thread], Stopped 
2022-04-28 17:04:38 [Test worker] INFO  kafka.controller.RequestSendThread - [Controller-0-to-broker-0-send-thread], Shutdown completed
2022-04-28 17:04:38 [Test worker] INFO  kafka.controller.KafkaController - [Controller 0]: Broker 0 resigned as the controller
2022-04-28 17:04:38 [ZkClient-EventThread-25-127.0.0.1:50286] INFO  org.I0Itec.zkclient.ZkEventThread - Terminate ZkClient event thread.
2022-04-28 17:04:38 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x1806ff3832e0001
2022-04-28 17:04:38 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x1806ff3832e0001 closed
2022-04-28 17:04:38 [Test worker-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x1806ff3832e0001
2022-04-28 17:04:38 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:50294 which had sessionid 0x1806ff3832e0001
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 0], shut down completed
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.utils.ZKCheckedEphemeral - Creating /controller (is it secure? false)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.utils.ZKCheckedEphemeral - Result of znode creation is: OK
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.server.ZookeeperLeaderElector - 1 successfully elected as leader
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Broker 1 starting become controller state transition
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Initialized controller epoch to 1 and zk version 0
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Controller 1 incremented epoch to 2
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], shutting down
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], Starting controlled shutdown
2022-04-28 17:04:38 [Controller-1-to-broker-1-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-1-to-broker-1-send-thread], Starting 
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Partitions undergoing preferred replica election: 
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Partitions that completed preferred replica election: 
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Resuming preferred replica election for partitions: 
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Partitions being reassigned: Map()
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Partitions already reassigned: Set()
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Resuming reassignment of partitions: Map()
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: List of topics to be deleted: 
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: List of topics ineligible for deletion: __consumer_offsets,messages
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Currently active brokers in the cluster: Set(1)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Currently shutting brokers in the cluster: Set()
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Current list of topics in the cluster: Set(messages, __consumer_offsets)
2022-04-28 17:04:38 [Controller-1-to-broker-1-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-1-to-broker-1-send-thread], Controller 1 connected to localhost:50296 (id: 1 rack: null) for sending state change requests
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 1]: Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=messages,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=messages,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 1]: Started replica state machine with initial state -&gt; Map([Topic=__consumer_offsets,Partition=48,Replica=1] -&gt; OnlineReplica, [Topic=messages,Partition=0,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=39,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=21,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=33,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=messages,Partition=1,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -&gt; OnlineReplica, [Topic=messages,Partition=0,Replica=1] -&gt; OnlineReplica, [Topic=messages,Partition=1,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=9,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=17,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=6,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=19,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=49,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=45,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=34,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=26,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=43,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=46,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=15,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=42,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=32,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=4,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=0,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=30,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=41,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=20,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=14,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=18,Replica=1] -&gt; OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=47,Replica=0] -&gt; ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=35,Replica=0] -&gt; ReplicaDeletionIneligible)
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,48] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,46] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,44] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,42] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,32] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,30] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,28] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,26] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [messages,1] since its associated leader epoch 1 is not higher than the current leader epoch 1
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,40] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,38] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,36] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,34] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,16] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,14] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,12] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,10] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,24] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,22] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,20] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,18] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,0] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [messages,0] since its associated leader epoch 1 is not higher than the current leader epoch 1
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,8] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,6] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,4] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [kafka-request-handler-1] WARN  state.change.logger - Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 2 for partition [__consumer_offsets,2] since its associated leader epoch 0 is not higher than the current leader epoch 0
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,19] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,19] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,47] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,47] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,29] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,29] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,41] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,41] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,39] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,39] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,17] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,17] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,33] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,33] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,21] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,21] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,3] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,3] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,5] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,5] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,23] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,23] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,15] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,15] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,11] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,11] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,13] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,13] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,49] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,49] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,37] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,37] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,31] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,31] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,25] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,25] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,45] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,45] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,27] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,27] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,43] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,43] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,35] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,35] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,7] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,7] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,9] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,9] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [__consumer_offsets,1] from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica for partition [__consumer_offsets,1] is alive. Live brokers are: [Set(1)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:73)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:200)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:115)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:112)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:112)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:67)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:342)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:160)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:85)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:154)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:153)
	at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:825)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:72)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Started partition state machine with initial state -&gt; Map([__consumer_offsets,19] -&gt; OfflinePartition, [__consumer_offsets,30] -&gt; OnlinePartition, [__consumer_offsets,47] -&gt; OfflinePartition, [__consumer_offsets,29] -&gt; OfflinePartition, [__consumer_offsets,41] -&gt; OfflinePartition, [__consumer_offsets,39] -&gt; OfflinePartition, [__consumer_offsets,10] -&gt; OnlinePartition, [__consumer_offsets,17] -&gt; OfflinePartition, [__consumer_offsets,14] -&gt; OnlinePartition, [__consumer_offsets,40] -&gt; OnlinePartition, [messages,1] -&gt; OnlinePartition, [__consumer_offsets,18] -&gt; OnlinePartition, [__consumer_offsets,0] -&gt; OnlinePartition, [__consumer_offsets,26] -&gt; OnlinePartition, [__consumer_offsets,24] -&gt; OnlinePartition, [__consumer_offsets,33] -&gt; OfflinePartition, [__consumer_offsets,20] -&gt; OnlinePartition, [__consumer_offsets,21] -&gt; OfflinePartition, [__consumer_offsets,3] -&gt; OfflinePartition, [__consumer_offsets,22] -&gt; OnlinePartition, [__consumer_offsets,5] -&gt; OfflinePartition, [__consumer_offsets,12] -&gt; OnlinePartition, [__consumer_offsets,8] -&gt; OnlinePartition, [__consumer_offsets,23] -&gt; OfflinePartition, [__consumer_offsets,15] -&gt; OfflinePartition, [__consumer_offsets,11] -&gt; OfflinePartition, [__consumer_offsets,48] -&gt; OnlinePartition, [__consumer_offsets,13] -&gt; OfflinePartition, [__consumer_offsets,49] -&gt; OfflinePartition, [__consumer_offsets,6] -&gt; OnlinePartition, [__consumer_offsets,28] -&gt; OnlinePartition, [__consumer_offsets,4] -&gt; OnlinePartition, [__consumer_offsets,37] -&gt; OfflinePartition, [__consumer_offsets,31] -&gt; OfflinePartition, [__consumer_offsets,44] -&gt; OnlinePartition, [__consumer_offsets,42] -&gt; OnlinePartition, [__consumer_offsets,34] -&gt; OnlinePartition, [__consumer_offsets,46] -&gt; OnlinePartition, [messages,0] -&gt; OnlinePartition, [__consumer_offsets,25] -&gt; OfflinePartition, [__consumer_offsets,45] -&gt; OfflinePartition, [__consumer_offsets,27] -&gt; OfflinePartition, [__consumer_offsets,32] -&gt; OnlinePartition, [__consumer_offsets,43] -&gt; OfflinePartition, [__consumer_offsets,36] -&gt; OnlinePartition, [__consumer_offsets,35] -&gt; OfflinePartition, [__consumer_offsets,7] -&gt; OfflinePartition, [__consumer_offsets,9] -&gt; OfflinePartition, [__consumer_offsets,38] -&gt; OnlinePartition, [__consumer_offsets,1] -&gt; OfflinePartition, [__consumer_offsets,2] -&gt; OnlinePartition, [__consumer_offsets,16] -&gt; OnlinePartition)
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Broker 1 is ready to serve as the new controller with epoch 2
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: Starting preferred replica leader election for partitions 
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Invoking state change to OnlinePartition for partitions 
2022-04-28 17:04:38 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1806ff3832e0002 type:delete cxid:0xc1 zxid:0xcd txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  kafka.controller.KafkaController - [Controller 1]: starting the partition rebalance scheduler
2022-04-28 17:04:38 [kafka-request-handler-2] INFO  kafka.controller.KafkaController - [Controller 1]: Shutting down broker 1
2022-04-28 17:04:38 [delete-topics-thread-1] INFO  k.c.TopicDeletionManager$DeleteTopicsThread - [delete-topics-thread-1], Starting 
2022-04-28 17:04:38 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  k.s.ZookeeperLeaderElector$LeaderChangeListener - New leader is 1
2022-04-28 17:04:38 [kafka-request-handler-2] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Invoking state change to OnlinePartition for partitions [messages,1]
2022-04-28 17:04:38 [kafka-request-handler-2] ERROR state.change.logger - Controller 1 epoch 2 encountered error while electing leader for partition [messages,1] due to: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1.
2022-04-28 17:04:38 [kafka-request-handler-2] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [messages,1] from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [messages,1] due to: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:362)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:202)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:141)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:140)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:140)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:268)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:263)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:259)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:224)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:87)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:62)
	at java.lang.Thread.run(Thread.java:748)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:191)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	... 22 common frames omitted
2022-04-28 17:04:38 [kafka-request-handler-2] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Invoking state change to OnlinePartition for partitions [messages,0]
2022-04-28 17:04:38 [kafka-request-handler-2] ERROR state.change.logger - Controller 1 epoch 2 encountered error while electing leader for partition [messages,0] due to: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1.
2022-04-28 17:04:38 [kafka-request-handler-2] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [messages,0] from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [messages,0] due to: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:362)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:202)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:141)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:140)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:140)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:268)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:263)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:259)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:224)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:87)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:62)
	at java.lang.Thread.run(Thread.java:748)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:191)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	... 22 common frames omitted
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], Remaining partitions to move: messages-0,messages-1
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], Error code from controller: 0
2022-04-28 17:04:38 [Test worker] WARN  kafka.server.KafkaServer - [Kafka Server 1], Retrying controlled shutdown after the previous attempt failed...
2022-04-28 17:04:38 [kafka-request-handler-4] INFO  kafka.controller.KafkaController - [Controller 1]: Shutting down broker 1
2022-04-28 17:04:38 [kafka-request-handler-4] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Invoking state change to OnlinePartition for partitions [messages,1]
2022-04-28 17:04:38 [kafka-request-handler-4] ERROR state.change.logger - Controller 1 epoch 2 encountered error while electing leader for partition [messages,1] due to: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1.
2022-04-28 17:04:38 [kafka-request-handler-4] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [messages,1] from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [messages,1] due to: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:362)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:202)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:141)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:140)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:140)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:268)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:263)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:259)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:224)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:87)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:62)
	at java.lang.Thread.run(Thread.java:748)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:191)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	... 22 common frames omitted
2022-04-28 17:04:38 [kafka-request-handler-4] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Invoking state change to OnlinePartition for partitions [messages,0]
2022-04-28 17:04:38 [kafka-request-handler-4] ERROR state.change.logger - Controller 1 epoch 2 encountered error while electing leader for partition [messages,0] due to: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1.
2022-04-28 17:04:38 [kafka-request-handler-4] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [messages,0] from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [messages,0] due to: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:362)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:202)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:141)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:140)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:140)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:268)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:263)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:259)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:224)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:87)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:62)
	at java.lang.Thread.run(Thread.java:748)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:191)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	... 22 common frames omitted
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], Remaining partitions to move: messages-0,messages-1
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], Error code from controller: 0
2022-04-28 17:04:38 [Test worker] WARN  kafka.server.KafkaServer - [Kafka Server 1], Retrying controlled shutdown after the previous attempt failed...
2022-04-28 17:04:38 [kafka-request-handler-6] INFO  kafka.controller.KafkaController - [Controller 1]: Shutting down broker 1
2022-04-28 17:04:38 [kafka-request-handler-6] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Invoking state change to OnlinePartition for partitions [messages,1]
2022-04-28 17:04:38 [kafka-request-handler-6] ERROR state.change.logger - Controller 1 epoch 2 encountered error while electing leader for partition [messages,1] due to: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1.
2022-04-28 17:04:38 [kafka-request-handler-6] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [messages,1] from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [messages,1] due to: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:362)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:202)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:141)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:140)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:140)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:268)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:263)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:259)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:224)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:87)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:62)
	at java.lang.Thread.run(Thread.java:748)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [messages,1] besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:191)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	... 22 common frames omitted
2022-04-28 17:04:38 [kafka-request-handler-6] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Invoking state change to OnlinePartition for partitions [messages,0]
2022-04-28 17:04:38 [kafka-request-handler-6] ERROR state.change.logger - Controller 1 epoch 2 encountered error while electing leader for partition [messages,0] due to: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1.
2022-04-28 17:04:38 [kafka-request-handler-6] ERROR state.change.logger - Controller 1 epoch 2 initiated state change for partition [messages,0] from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [messages,0] due to: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:362)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:202)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:141)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:140)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:140)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:268)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:263)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:263)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:259)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:224)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:87)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:62)
	at java.lang.Thread.run(Thread.java:748)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [messages,0] besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:191)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:339)
	... 22 common frames omitted
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], Remaining partitions to move: messages-0,messages-1
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], Error code from controller: 0
2022-04-28 17:04:38 [Test worker] WARN  kafka.server.KafkaServer - [Kafka Server 1], Retrying controlled shutdown after the previous attempt failed...
2022-04-28 17:04:38 [Test worker] WARN  kafka.server.KafkaServer - [Kafka Server 1], Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2022-04-28 17:04:38 [Test worker] INFO  kafka.network.SocketServer - [Socket Server on Broker 1], Shutting down
2022-04-28 17:04:38 [Test worker] INFO  kafka.network.SocketServer - [Socket Server on Broker 1], Shutdown completed
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaRequestHandlerPool - [Kafka Request Handler on Broker 1], shutting down
2022-04-28 17:04:38 [Test worker] INFO  kafka.server.KafkaRequestHandlerPool - [Kafka Request Handler on Broker 1], shut down completely
2022-04-28 17:04:38 [Test worker] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Fetch], Shutting down
2022-04-28 17:04:39 [ThrottledRequestReaper-Fetch] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Fetch], Stopped 
2022-04-28 17:04:39 [Test worker] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Fetch], Shutdown completed
2022-04-28 17:04:39 [Test worker] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Produce], Shutting down
2022-04-28 17:04:39 [kafka-coordinator-heartbeat-thread | sampleRawConsumer] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator localhost:50296 (id: 2147483646 rack: null) dead for group sampleRawConsumer
2022-04-28 17:04:40 [ThrottledRequestReaper-Produce] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Produce], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  k.s.ClientQuotaManager$ThrottledRequestReaper - [ThrottledRequestReaper-Produce], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  kafka.server.KafkaApis - [KafkaApi-1] Shutdown complete.
2022-04-28 17:04:40 [Test worker] INFO  kafka.server.ReplicaManager - [Replica Manager on Broker 1]: Shutting down
2022-04-28 17:04:40 [Test worker] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 1] shutting down
2022-04-28 17:04:40 [Test worker] INFO  kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 1] shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutting down
2022-04-28 17:04:40 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutting down
2022-04-28 17:04:40 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  kafka.server.ReplicaManager - [Replica Manager on Broker 1]: Shut down completely
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutting down
2022-04-28 17:04:40 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Shutting down.
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutting down
2022-04-28 17:04:40 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutting down
2022-04-28 17:04:40 [ExpirationReaper-1] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  k.s.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-1], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  kafka.coordinator.GroupCoordinator - [GroupCoordinator 1]: Shutdown complete.
2022-04-28 17:04:40 [Test worker] INFO  kafka.log.LogManager - Shutting down.
2022-04-28 17:04:40 [Test worker] INFO  kafka.log.LogCleaner - Shutting down the log cleaner.
2022-04-28 17:04:40 [Test worker] INFO  kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Shutting down
2022-04-28 17:04:40 [kafka-log-cleaner-thread-0] INFO  kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  kafka.log.LogManager - Shutdown complete.
2022-04-28 17:04:40 [Test worker] INFO  k.c.TopicDeletionManager$DeleteTopicsThread - [delete-topics-thread-1], Shutting down
2022-04-28 17:04:40 [delete-topics-thread-1] INFO  k.c.TopicDeletionManager$DeleteTopicsThread - [delete-topics-thread-1], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  k.c.TopicDeletionManager$DeleteTopicsThread - [delete-topics-thread-1], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  k.controller.PartitionStateMachine - [Partition state machine on Controller 1]: Stopped partition state machine
2022-04-28 17:04:40 [Test worker] INFO  kafka.controller.ReplicaStateMachine - [Replica state machine on controller 1]: Stopped replica state machine
2022-04-28 17:04:40 [Test worker] INFO  kafka.controller.RequestSendThread - [Controller-1-to-broker-1-send-thread], Shutting down
2022-04-28 17:04:40 [Controller-1-to-broker-1-send-thread] INFO  kafka.controller.RequestSendThread - [Controller-1-to-broker-1-send-thread], Stopped 
2022-04-28 17:04:40 [Test worker] INFO  kafka.controller.RequestSendThread - [Controller-1-to-broker-1-send-thread], Shutdown completed
2022-04-28 17:04:40 [Test worker] INFO  kafka.controller.KafkaController - [Controller 1]: Broker 1 resigned as the controller
2022-04-28 17:04:40 [ZkClient-EventThread-63-127.0.0.1:50286] INFO  org.I0Itec.zkclient.ZkEventThread - Terminate ZkClient event thread.
2022-04-28 17:04:40 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x1806ff3832e0002
2022-04-28 17:04:40 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x1806ff3832e0002 closed
2022-04-28 17:04:40 [Test worker-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x1806ff3832e0002
2022-04-28 17:04:40 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:50297 which had sessionid 0x1806ff3832e0002
2022-04-28 17:04:40 [Test worker] INFO  kafka.server.KafkaServer - [Kafka Server 1], shut down completed
2022-04-28 17:04:40 [ZkClient-EventThread-20-127.0.0.1:50286] INFO  org.I0Itec.zkclient.ZkEventThread - Terminate ZkClient event thread.
2022-04-28 17:04:40 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x1806ff3832e0000
2022-04-28 17:04:40 [Test worker] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x1806ff3832e0000 closed
2022-04-28 17:04:40 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:50292 which had sessionid 0x1806ff3832e0000
2022-04-28 17:04:40 [Test worker-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x1806ff3832e0000
2022-04-28 17:04:40 [Test worker] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2022-04-28 17:04:40 [Test worker] ERROR o.a.zookeeper.server.ZooKeeperServer - ZKShutdownHandler is not registered, so ZooKeeper server won't take any action on ERROR or SHUTDOWN server state changes
2022-04-28 17:04:40 [Test worker] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2022-04-28 17:04:40 [Test worker] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2022-04-28 17:04:40 [Test worker] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2022-04-28 17:04:40 [ProcessThread(sid:0 cport:50286):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2022-04-28 17:04:40 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2022-04-28 17:04:40 [Test worker] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2022-04-28 17:04:40 [NIOServerCxn.Factory:/127.0.0.1:0] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2022-04-28 17:04:41 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
</pre>
</span>
</div>
</div>
<div id="footer">
<p>
<div>
<label class="hidden" id="label-for-line-wrapping-toggle" for="line-wrapping-toggle">Wrap lines
<input id="line-wrapping-toggle" type="checkbox" autocomplete="off"/>
</label>
</div>Generated by 
<a href="http://www.gradle.org">Gradle 3.5.1</a> at 28 Apr, 2022 5:04:42 PM</p>
</div>
</div>
</body>
</html>
